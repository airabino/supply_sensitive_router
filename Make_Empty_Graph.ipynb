{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da219a36-3bd5-483f-9b4b-531478cdf374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src\n",
    "from src.reload import deep_reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae2e66-7ffe-41a2-aeb9-e6963b18988b",
   "metadata": {},
   "source": [
    "Please run make_data_structure.sh prior to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef3aae-bc9e-483b-bde9-196072d6339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Making the Place graph\n",
    "'''\n",
    "deep_reload(src)\n",
    "\n",
    "# Loading input files\n",
    "gdf_place = gpd.read_file('Data/Place/tl_2023_06_place.shp')\n",
    "\n",
    "df_place = pd.read_excel(\n",
    "    'Data/Place/populations.xlsx',\n",
    "    skiprows = 3, skipfooter = 5,\n",
    ")\n",
    "\n",
    "df_place = df_place.rename(columns = {'Unnamed: 0': 'Name', 'Unnamed: 1': 'Base'})\n",
    "\n",
    "df_place_names = df_place['Name'].to_numpy()\n",
    "df_place_population = df_place[2022].to_numpy()\n",
    "gdf_place_names = gdf_place['NAME'].to_numpy()\n",
    "\n",
    "# Adding populations to geometries\n",
    "\n",
    "pop = {}\n",
    "\n",
    "for name in gdf_place_names:\n",
    "\n",
    "    for idx, check_name in enumerate(df_place_names):\n",
    "\n",
    "        if name in check_name:\n",
    "\n",
    "            pop[name] = df_place_population[idx]\n",
    "            break\n",
    "\n",
    "populations = []\n",
    "\n",
    "for name in gdf_place_names:\n",
    "\n",
    "    populations.append(pop.get(name, 0))\n",
    "\n",
    "gdf_place['population'] = populations\n",
    "gdf_place['log_population'] = np.log(gdf_place['population'])\n",
    "\n",
    "# Selecting for places with at least 1,000 persons\n",
    "gdf_place_sel = gdf_place[gdf_place['population'] > 1e3]\n",
    "\n",
    "# Creating the graph - edges are Haversine distances\n",
    "lon, lat = np.array([x.coords.xy for x in gdf_place_sel.geometry.centroid]).T[0]\n",
    "names = gdf_place_sel['NAME'].to_numpy()\n",
    "pop = gdf_place_sel['population'].to_numpy()\n",
    "\n",
    "nodes = []\n",
    "\n",
    "for idx in range(len(names)):\n",
    "\n",
    "    node = {\n",
    "        'id': names[idx],\n",
    "        'x': lon[idx],\n",
    "        'y': lat[idx],\n",
    "        'population': pop[idx],\n",
    "        'type': 'place',\n",
    "    }\n",
    "\n",
    "    nodes.append(node)\n",
    "\n",
    "links = []\n",
    "\n",
    "for idx_s in range(len(names)):\n",
    "    for idx_t in range(len(names)):\n",
    "\n",
    "        link = {\n",
    "            'source': names[idx_s],\n",
    "            'target': names[idx_t],\n",
    "            'distance': src.utilities.haversine(\n",
    "                lon[idx_s], lat[idx_s], lon[idx_t], lat[idx_t],\n",
    "            )\n",
    "        }\n",
    "\n",
    "        links.append(link)\n",
    "    \n",
    "places = src.graph.graph_from_nlg({'nodes': nodes, 'links': links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56bf0c-ff49-49fa-9eda-d3171e43ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "places.number_of_nodes(), places.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d82c60-6e50-490b-a088-8b2af1e9dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the communities graph - communities determined by inverse distance\n",
    "'''\n",
    "deep_reload(src)\n",
    "\n",
    "# Adding inverse distances for maximal communities\n",
    "for source, adj in places._adj.items():\n",
    "    for target, edge in adj.items():\n",
    "\n",
    "        edge['inverse_distance'] = np.exp(-edge['distance'] / 10e3)\n",
    "\n",
    "# Computing the communities\n",
    "c = nx.community.greedy_modularity_communities(\n",
    "    places, weight = 'inverse_distance', resolution = 1,\n",
    ")\n",
    "\n",
    "# Making the communities graph - note that this graph has no edges\n",
    "communities = src.graph.graph_from_communities(places, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831708be-8fe3-4188-8544-fcc536ac1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities.number_of_nodes(), communities.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1efb9-ed48-4578-bf84-54825546bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading the communities from outside California to add to the graph\n",
    "'''\n",
    "\n",
    "filename = 'additional_places.json'\n",
    "\n",
    "additional_places = src.graph.graph_from_json(filename)\n",
    "\n",
    "graph_places = nx.union(communities, additional_places)\n",
    "\n",
    "src.graph.graph_to_json(graph_places, 'Outputs/places.json')\n",
    "\n",
    "places.number_of_nodes(), graph_places.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5f72a-683f-46fd-9269-93105e59b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading in the scharging station data\n",
    "'''\n",
    "\n",
    "with open('Data/AFDC/evse_stations.json', 'r') as file:\n",
    "    evse = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a0d9-687d-4ce9-b895-b8ffa7e0d06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Down-selecting for existing public DC stations in California\n",
    "'''\n",
    "stations_raw = []\n",
    "\n",
    "for station in evse['fuel_stations']:\n",
    "\n",
    "    checks = (\n",
    "        station['state'] == 'CA',\n",
    "        station['ev_dc_fast_num'] is not None,\n",
    "        station['access_code'] == 'public',\n",
    "        station['status_code'] == 'E',\n",
    "    )\n",
    "\n",
    "    if all(checks):\n",
    "\n",
    "        stations_raw.append(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381037d7-6bc7-4754-a114-16d1e9e30210",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merging equipment labeled as individual stations but actually forming a single station\n",
    "'''\n",
    "\n",
    "longitude = np.array([station['longitude'] for station in stations_raw])\n",
    "latitude = np.array([station['longitude'] for station in stations_raw])\n",
    "ids = np.array([station['id'] for station in stations_raw])\n",
    "networks = np.array([station['ev_network'] for station in stations_raw])\n",
    "\n",
    "x_s, x_f = np.meshgrid(longitude, longitude, indexing  = 'ij')\n",
    "y_s, y_f = np.meshgrid(latitude, latitude, indexing  = 'ij')\n",
    "\n",
    "distance = src.utilities.haversine(x_s, y_s, x_f, y_f)\n",
    "\n",
    "def none_then_zero(x):\n",
    "\n",
    "    if x is None:\n",
    "\n",
    "        return 0\n",
    "\n",
    "    else:\n",
    "\n",
    "        return x\n",
    "\n",
    "stations_merged = [station.copy() for station in stations_raw]\n",
    "\n",
    "drop = []\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "for idx, row in enumerate(distance):\n",
    "\n",
    "    if ids[idx] in drop:\n",
    "\n",
    "        continue\n",
    "\n",
    "    for col, dist in enumerate(row):\n",
    "\n",
    "        if (dist <= threshold) & (idx != col) & (networks[idx] == networks[col]):\n",
    "\n",
    "            drop.append(ids[col])\n",
    "\n",
    "            stations_merged[idx]['ev_dc_fast_num'] = (\n",
    "                none_then_zero(stations_raw[idx]['ev_dc_fast_num']) +\n",
    "                none_then_zero(stations_raw[col]['ev_dc_fast_num'])\n",
    "            )\n",
    "\n",
    "            stations_merged[idx]['ev_level2_evse_num'] = (\n",
    "                none_then_zero(stations_raw[idx]['ev_level2_evse_num']) +\n",
    "                none_then_zero(stations_raw[col]['ev_level2_evse_num'])\n",
    "            )\n",
    "\n",
    "stations_merged = [station for station in stations_merged if station['id'] not in drop]\n",
    "\n",
    "len(stations_merged), len(stations_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad3cb5-addd-48f1-9931-0724223a85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the stations graph\n",
    "'''\n",
    "\n",
    "df_stations = pd.DataFrame.from_dict(stations_merged)\n",
    "\n",
    "node_attributes = {\n",
    "    'x': 'lambda n: n[\"longitude\"]',\n",
    "    'y': 'lambda n: n[\"latitude\"]',\n",
    "    'n_dcfc': 'lambda n: n[\"ev_dc_fast_num\"]',\n",
    "    'n_acl2': 'lambda n: n[\"ev_level2_evse_num\"]',\n",
    "    'network': 'lambda n: n[\"ev_network\"]',\n",
    "    'name': 'lambda n: n[\"station_name\"]',\n",
    "    'address': 'lambda n: n[\"street_address\"]',\n",
    "    'city': 'lambda n: n[\"city\"]',\n",
    "    'state': 'lambda n: n[\"state\"]',\n",
    "    'zip': 'lambda n: n[\"zip\"]',\n",
    "    'access_code': 'lambda n: n[\"access_code\"]',\n",
    "    'status_code': 'lambda n: n[\"status_code\"]',\n",
    "    'type': 'lambda n: \"station\"',\n",
    "}\n",
    "\n",
    "nlg = src.graph.nlg_from_dataframe(df_stations, node_attributes)\n",
    "\n",
    "graph_station = src.graph.graph_from_nlg(nlg)\n",
    "\n",
    "mapping = {n: f'station_{n}' for n in graph_station.nodes}\n",
    "\n",
    "graph_station = nx.relabel_nodes(graph_station, mapping)\n",
    "\n",
    "graph_empty = nx.union(graph_places, graph_station)\n",
    "\n",
    "src.graph.graph_to_json(graph_empty, 'Outputs/graph_empty.json')\n",
    "\n",
    "graph_empty.number_of_nodes(), graph_empty.number_of_edges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
